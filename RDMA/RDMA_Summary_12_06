1.什么是RDMA,RDMA用来做什么
  全称：
	RDMA：Remote Direct Memory Access
  属性：
	一种高速网络访问技术，低延迟{架构}，高吞吐量{网卡}
  用途：
	在网络I/O的data path上解决服务器端数据处理的延迟
  原理：
	对照传统socket网络传输过程【插图socket protocol stack】
	1.Kernel bypass in data path
	  应用层的应用进程发起网络I/O操作时不通过中断陷入内核层，直接访问硬件驱动，这一过程中没有陷入内核带来的两次上下文切换，减少时间开销
	2.Zero copy in data path
	  应用层的应用进程发起网络I/O操作时，网络数据不会拷贝到内核层的内存段中，而是允许网卡直接访问应用层的内存段，在发起端减少两次内存拷贝，分别是从应用内存拷贝到内核内存和从内核层经过协议栈封装之后拷贝到网卡的软件发送队列sk_buff，同样在接收端也减少两次内存拷贝，极大的减少内存拷贝带来的时延，同时也释放cpu资源，同样的时间可以去服务应用【插图hidden cost】
	3.Protocol packing offload
  	  协议栈从原来的内核空间offload到网卡，网卡根据驱动程序的协议栈做协议封装后发送数据，消除cpu在内核空间做协议封装的过程，释放cpu资源

2.我要解决的问题
  RDMA可扩展性问题
  现象1：panda
  现象2：FaSST
  原因：
  研究方向：共享底层网络资源
3.相关工作
  HERD
  FaRM
  FaSST
  LITE
4.我的工作
  共享底层网络资源并向上提供抽象的网络资源访问服务
  性能，公平性，易用
  需要一个良好的设计
  按照发展的逻辑进行：
  第一阶段：简单共享
 	竞争共享访问模式
	|	|	|	|	|  虚拟资源
		
			|  实际资源
  问题：  
  	复用资源带来的是竞争问题，当多个虚拟资源同时使用同一个实际资源时会发生
      资源竞争，资源竞争最直接影响就是性能的损失，无法为每个虚拟资源做到服务性
      能保证，无公平性空间
  讨论：
	解决竞争问题的最直接方法是为每个虚拟资源提供独立的实际资源访问
      还有其他方法吗

  第二阶段：消除竞争，预留公平空间
	模拟独立访问模式
	需要对照系统概述图详细讲解是如何实现的
	|	|	|	|	|  虚拟资源
	-------------------------
			|  模拟独立访问执行
	-------------------------
			|  实际资源
	让模拟独立访问执行的实体去批量执行虚拟资源的请求
	相当于把原本一个完整的网络I/O在中间做了一个接力
	这样要求原本的同步I/O转变为异步I/O方式
  问题:
	1.当虚拟资源过多，而模拟独立访问执行的实体过少，会给虚拟资源的请求服
      务造成时延(比如有100个虚拟资源请求而处理每个资源请求需要1us，那么会对
	同一批处理的虚拟资源整体造成~100us的时延)，这时会需要多个模拟独立访问
	的实体来并行处理虚拟资源的请求而将时延降低到可以忽略的级别，怎么为虚拟
	资源分配这些实体以满足将引入的时延尽可能的降低，实体应该设置多少个？
	答：
		当虚拟资源对应的实际资源各不相同且应用层的执行实体也各不相同时，
	为每个实际资源设置一个模拟独立访问实体，这样可以将虚拟资源的服务隔离开
	来。
		当虚拟资源对应的实际资源相同且虚拟资源较多时，只使用一个执行实体
	会带来一定时延，设置多少个执行实体呢，从gRPC实验中得结论,当有24个应用
	线程满负荷(100% * 19 = 1900% CPU)在24个虚拟资源上执行网络I/O时，底层
	的3个执行实体线程利用率不超过40% * 3 = 120%
		当以上两种情况同时存在时，我们需要对这些模拟独立访问执行实体进行
	复用，如何将多个虚拟资源请求分配到最佳的执行实体，使得执行实体集合负载
	均衡？
		当前的做法：
				least-connections-algorithm
		可以讨论的做法：
				执行实体动态抢任务，不做虚拟资源到模拟独立访问实体	的固定映射
	#2.当并发虚拟资源请求分配到同一个实体上时，怎么为多个虚拟资源请求提供
	公平性服务，本质上是流调度QoS
		当前的做法：
				FIFO

  第三阶段：减小虚拟资源和模拟独立访问执行的断层跨度(有可能消除上述第一个问题)
	中间模拟独立访问执的时延仍然需要压缩，需要将时间向应用层压缩，然后空出时间来做流调度和QoS
