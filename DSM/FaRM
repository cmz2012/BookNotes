fast remote memory
FaRM 是一种使用RDMA来改善延迟和带宽的主存分布式计算平台，性能相比于使用TCP/IP主存系统的技术提升了一个数量级。
FaRM把集群中机器的主存作为一个共享地址空间。
FaRM提供两种机制来改善程序性能：在RDMA上的无锁读，支持收集对象和函数迁移来高效使用单机器事务。
它使用RDMA来直接访问共享地址空间的数据和高效的发送数据。
一个20台机器的集群每秒可以执行1.67亿次键值对查询，仅有31微秒的时延。

简介：
        因为把工作集数据全部载入主存中，消除了硬盘或闪存的中间耗费，使得程序可以随机访问小型数据，但是网络通信
    却成为了瓶颈。实验表明：使用TCP/IP的分布式内存计算比单机存储计算性能要差的多，虽然单机环境下数据访问请求代价很高。
    FaRM使用RDMA写来实现快速的消息传递原语，这比在相同以太网环境下比TCP/IP性能提高了一个数量级。使用单边RDMA读对于
    在大多数负载上出现的只读操作实现了两倍的性能改善。但是我们没有非常好的取得这样理想的性能。我们对操作系统和NIC驱动
    仔细的做优化和更改把性能提升了1/8。
        FaRM机器把数据存在主存中，也执行应用线程。这就可以进行局部性优化，这很重要因为访问局部内存比RDMA快23倍。
    线程能够使用ACID的事务而严格串行地在地址空间分配，读，写和释放对象而不需要担心对象的位置。
    事务使用利用RDMA优势带有经过优化的两级提交协议的乐观并发控制。将日志副本写到多个SSD上去，FaRM可以获得可用性
    和持续性，但也可以作为一个缓存。(？)
        FaRM提供两种机制来改善性能，这只需要对代码做一些局部修改：多次无锁读可以使用一次RDMA操作完成，并且这些读是由
    事务保证严格串行的；支持对象收集和函数迁移来允许应用程序把分布式事务替换成经过优化的单机事务。
    我们在FaRM上设计实现了一个新型哈希表算法，它把hopscotch哈希与链式化和关联性结合起来是的空间利用率高，同时只需要
    少量的RDMA读操作来应用于查询操作：在90%的并发上小型对象的读只需要1.04次RDMA读操作。
    通过利用FaRM对收集相关对象和函数迁移的支持，我们对插入，更新和移除操作进行优化。
    
通信原语：
        FaRM使用单边RDMA读来直接访问数据，并且使用RDMA写来实现一种快速消息传递原语。这个原语使用一个环形缓冲区来实现一个单向信道。
    缓冲区放在receiver上，对于每一对sender和receiver只有一个缓冲区。缓冲区未使用的部分（标记为未处理和未使用）是被清零使得receiver
    能都检测到新的消息。receiver间歇性的从Head位置提取数据来检测新消息。头部中任何非零的值L都表示有一个长度为L的新消息。
    receiver然后就轮询提取直到报文尾部：当结果变为非零时，整个消息就被接收完毕，因为RDMA写是以逐渐增加的地址序列来执行的。
    之后，消息被交付给应用层，并且一旦被应用层处理完之后，receiver就将消息缓冲区清零并且将head指针向前(增长的方向)移动。
        发送者使用RDMA来讲消息写到缓冲区的尾部然后每次发送时都将尾指针向增加的方向移动。发送方会维护接收方头指针的一个本地副本并且从来不会
    在写入消息时越过这个点。接收方通过使用RDMA将当前head的值写到发送方的副本里，稍慢一步告诉发送方经过处理的缓冲区空间已经可用了。
    为了减少中间耗费，接收方只在处理完缓冲区的一半后才更新发送方的副本（头指针）。发送方的头指针副本总是滞后于接收方的头指针，因此也就保证了
    发送方绝不会写覆盖未经处理的消息。
        轮询poll的中间耗费随着信道(channel)数量的增加而线性增长。因此我们从一个线程中建立一个连接远程机器的单信道。在78台机器上我们发现轮询poll的
    中间耗费几乎可以忽略不算。我们也发现在这种规模上，RDMA写和轮询poll要比更复杂的infiniband发送和接受动作显著地表现的更好一些。在大型集群上，
    也许使用RDMA带有immediate的写配上共享接收队列SRQ更好，这会使得轮询poll的中间耗费是一个常量。
        我们的实现使用一个连续的环形缓冲区而不是许多缓冲区连接成一个环状来对于大小变化的消息提供更好的内存利用率。此外，【35】里面接收方在消息中
    外带对发送方头指针的更新数据。
        我们在用40G的RoCE网络连接的20台主机的集群环境下跑了一个微测试来比较FaRM的通信原语和TCP/IP的性能。每台机器运行一定数量的线程，以一种全互联
    的通信模式发送从一个随机的远程机器内存中随机读取一块的请求。图2展示了每台机器的平均请求率，每台机器都已经为了达到峰值吞吐量做了配置优化。
    图左边，packet的速率是FaRM通信原语的瓶颈所在，到了右边，通信瓶颈就是比特率。？？？。单边RDMA读操作在2KB的请求大小下达到了33G的比特率，并且
    在请求大小大于8KB时比特率在35G附近饱和。
        FaRM的基于RDMA消息发送模式在16到512字节范围内比TCP/IP的请求速率快11倍到9倍之间，这个数据大小是数据中心应用的典型规模。单边RDMA读操作在
    数据大小提升到256字节时会获得额外的2倍性能提升，因为它只要求一半的网络包（单边的优势）。我们期望这个性能间的间隔能随着下一代支持4倍消息率的NIC
    能持续增加。单边RDMA读操作不干涉远端的CPU而且基于RDMA的发送消息模式将会是CPU BOUND。
        我们也比较了UDP的吞吐量，并且观察到它比TCP吞吐量的一半还要少。
        图3展示了在极限请求速率和为了最小化延迟而只使用两台机器的环境下的平均请求延迟。TCP/IP在极限请求速率的条件下，延迟至少是基于RDMA的发送消息
    模式在所有请求大小下的145倍。对于请求大小提升到256字节时，通过两个额外的因素使用单边RDMA读来减少延迟。在一个没有加载的系统中（负荷不重的情况下），
    RDMA读的延迟至少比TCP/IP低12倍，并且在所以请求大小的情况下比基于RDMA的消息发送模式要低3倍。微测试表明FaRM的通信原语可以同时取得低延迟和高消息率。
        对于这两种通信原语，取得这样的性能水平是不一般的，需要解决一些问题。第一个问题就是：RDMA操作的性能会随着我们增加为远程访问而注册的内存的数量
    显著下降。原因就是：NIC用完了缓存所有页表的空间。因此它不断地通过PCI总线从系统内存中取页表记录。
        我们通过使用更大的页来减少NIC页表中的记录数量解决记录数量过多的问题。不行的是，windows和linux下现存支持的大页不能消除所有的取操作,因为FaRM
    注册的内存太多了。因此，我们实现了phyCo，它是一个内核驱动，可以在系统启动时分配大量物理上连续并且本身对齐的2GB内存区域(2GB是我们NIC支持的最大
    内存页)。PhyCo把这些内存区域映射到FaRM的虚拟地址空间里以2GB边缘对齐。这样我们就能修改NIC驱动来使用2GB的内存页了，而且这把每块内存区域的页表条目
    从超过50万降低到只有一个条目。
        我们运行随机读取测试来比较当内存区域用VirtualAlloc和PhyCo分配时的64字节RDMA读操作的请求速率。图4展示使用VirtualAlloc时，请求速率在NIC注册
    的内存超过16MB时降到原来的1/4。在PyhCo下，即便在注册100GB内存时，请求速率也是保持不变。
        我们也观察到当集群规模增加时，请求速率会显著降低，因为NIC耗尽了存储QP数据的空间。在每对线程之间使用一个QP，每台机器就需要2×m×t×t个QP，m是
    机器的数量，t是每台机器的线程数。我们用单连接来连接一个线程和远程机器把这个QP数量减少到2×m×t。而且，我们以NUMA感知的方式引入在q个线程间共享一个QP
    ，这就使得每台机器一共只需要2×m×t/q个QP对。这用并行化换取NIC上QP数据量的减少。
        我们改变集群规模和q的值来运行64字节传输的随机读取测试。图5展示了q的最优值依赖于集群的规模。q越小，并行化越好，共享耗费越低，也使得在小型集群
    上有更好的性能，但是在大型集群它们也需要更多的QP数据并且引起性能上的损失。我们期望在以后使用Dynamically Connected Transport来解决这个问题，它
    可以通过按需建立连接来改善可扩展性。
        先前的实验表明使用中断和阻塞会将RDMA的时延增加4倍。因此，我们使用基于事件的编程模型。每个FaRM机器运行一个用户级线程，并且把它和硬件线程连接
    起来。这些线程运行一个事件循环来执行应用程序的工作项，轮询poll基于RDMA消息的到来和RDMA请求的完成。这个POLL操作是在用户级上完成，不需要操作系统的干预
    
分布式内存管理：
        FaRM的共享地址空间由许多2GB的共享内存区域组成，它们是内存映射，恢复和NIC用来进行RDMA注册的基本单元。在这个共享地址空间中对象的地址是由两部
    分组成。一部分是32位的区域标识符，另一部分是32位的相对于区域起始地址的偏移量。为了访问一个对象，FaRM使用一致性哈希的一种形式来把区域标识符
    映射到存储这个对象的机器上。如果这个内存区域是存储在本地，FaRM就获取内存区域的起始地址并使用本地内存访问。否则的话，FaRM就和远程机器通信来
    获取对这片内存区域的访问权限然后用它(地址的偏移量和对象的大小)来建立一个RDMA请求。访问远程内存区域的权限会被缓存下来用来改善性能。
        一致性哈希使用one-hop分布式哈希表实现。(???)每台机器通过把他的IP地址和K个哈希函数进行哈希运算映射到K个虚拟环中。FaRM使用多个环来允许多块
    在内存云中对多个内存区域并行恢复，而且也改善了负载均衡。我们目前使用K=100个哈希函数。32位的共享区域标识符能识别一个环和在环上的位置。区域的主备份
    和副本存储在R个机器上紧随着环上内存区域的位置。图7展示了一个简单的例子，k=3和r=3。把内存区域映射到机器上可以在已知集群上机器的集合来进行本地计算。
    集群成员身份可以使用zookeeper来可靠的维持。
        内存分配者是以三级体系来组织的：slabs,blocks,和regions 来减少同步带来的中间消耗(类似于并行分配)。在最低层上，线程有私有的slab分配器，可以
    从大block中分配出小型对象。每个block用来分配同样大小的对象。FaRM支持从64字节到1MB范围内256种不同尺寸。尺寸是可以选择的，因此平均碎片只有1.8%，
    最大碎片只有3.6%。对象是从可以容纳的最小尺寸类别里分配的。Slab分配器用每个对象头部中的一位来标记它已经被分配出去了。当一次分配或者释放对象的任务
    提交时，这个状态被重新生成，在恢复来重构分配器数据结构期间，这个状态也会被扫描。
        blocks是从一个机器范围的block分配器获得的，这个分配器从共享内存中分配blocks。它把内存区域划分成大小是1MB倍数的blocks。每个内存区域有一张
    表，表里包含每个block的8字节的分配状态。这个内存区域是从集群范围的region分配器处获得的。内存区域分配器使用PhyCo为region分配内存然后为NIC注册
    这块内存区域来允许远程访问。它通过随机的选择一个ring和环上的一个位置来为这个region选择一个标识符，这可以确保本地结点存储在主备份上。与region
    和block分配相关的信息在分配时会同样被复制。
        FaRM允许应用程序在分配对象时提供一个分配提示，就是一个存在对象的地址。FaRM尝试以下面的顺序来分配地址：和提示的地址在同一个block里，在同一个
    region里，或者在同一个虚拟ring中和这个region邻近的位置。这确保被分配的对象和提示的地址在主备份和副本上即便失败和重新配置后有很大的概率保持并
    置排列。如果提示的地址是存储在另一个server上，那么这次分配就使用一次RPC对远程server进行执行。
    
事务：
        FaRM支持分布式事务作为一种确保一致性的通用机制。我们的实现是用乐观并发控制和两级提交来确保严格序列化。一个事务上下文记录被事务读取的对象
    的版本号(读集合)，被事务写过的对象版本号(写集合)和它缓存的写。在提交时，机器以coordinator身份来运行事务。向所有参与者发送准备消息而开始事务
    ，参与者是写集合里对象的主备份和复制备份。主备份锁住被修改的对象并且主备份和复制备份在发送回复之前都会记录下这个消息。从所有参与者接收到回复后，
    coordinator就发送validate消息给读集合里对象的主备份来检查被事务读的版本是不是最新的。如果读集合validation成功，coordinator就先给参与者的复制
    备份发送提交消息，再给参与者的主备份发送。主备份更新被修改的对象然后解锁他们，主备份和复制备份都会记录这个提交消息。如果有任何被修改的对象是被
    锁住的，或者如果读集合validation失败了，或者如果coordinator不能收到所有prepare和validate消息，事务就会终止。
        FaRM副本把日志保存在SSD上。为了改善日志性能，他们使用一些MB的非易失性RAM来保存环形消息缓冲和缓存日志条目。当缓冲区填满时，这些条目被清空，
    并且当日志是半满的时候，日志清理也会被触发。这些日志是用来实现一个并行恢复机制，类似于RAMCloud。
        两级提交协议是使用基于RDMA的消息模式实现的，这通过实验展示它的时延很低。这降低了冲突并且通过减少持有锁的时间来改善性能。虽然有这些优化，两级提
    交也许代价比较高而不能在一般情况操作下实现。
        FaRM提供两种机制来在普通情况下取得好性能：单机事务和无锁化只读操作。应用可以通过收集在同一主备份和同一复制备份上执行的事务所访问的对象和通过
    将事务迁移到主备份上来使用单机事务。这种情况下，写集合加锁和读集合validation是本地的。因此，prepare和validation消息是不需要的，并且主备份只需要
    在解锁被修改的对象之前发送一个带有缓存写的提交消息给复制备份。此外，我们使用两种加锁模式：允许无锁读时的模式下，对象先加锁；在独占模式下，主备份
    在更新对象前先加锁对象（在提交消息被提交给复制备份后）。单机事务通过减少消息数量和减小加锁动作的延迟来改善性能。
    
无锁操作：
    FaRM提供无锁读
     
        
    
    
