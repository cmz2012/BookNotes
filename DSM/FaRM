fast remote memory
FaRM 是一种使用RDMA来改善延迟和带宽的主存分布式计算平台，性能相比于使用TCP/IP主存系统的技术提升了一个数量级。
FaRM把集群中机器的主存作为一个共享地址空间。
FaRM提供两种机制来改善程序性能：在RDMA上的无锁读，支持收集对象和函数迁移来高效使用单机器事务。
它使用RDMA来直接访问共享地址空间的数据和高效的发送数据。
一个20台机器的集群每秒可以执行1.67亿次键值对查询，仅有31微秒的时延。

简介：
        因为把工作集数据全部载入主存中，消除了硬盘或闪存的中间耗费，使得程序可以随机访问小型数据，但是网络通信
    却成为了瓶颈。实验表明：使用TCP/IP的分布式内存计算比单机存储计算性能要差的多，虽然单机环境下数据访问请求代价很高。
    FaRM使用RDMA写来实现快速的消息传递原语，这比在相同以太网环境下比TCP/IP性能提高了一个数量级。使用单边RDMA读对于
    在大多数负载上出现的只读操作实现了两倍的性能改善。但是我们没有非常好的取得这样理想的性能。我们对操作系统和NIC驱动
    仔细的做优化和更改把性能提升了1/8。
        FaRM机器把数据存在主存中，也执行应用线程。这就可以进行局部性优化，这很重要因为访问局部内存比RDMA快23倍。
    线程能够使用ACID的事务而严格串行地在地址空间分配，读，写和释放对象而不需要担心对象的位置。
    事务使用利用RDMA优势带有经过优化的两级提交协议的乐观并发控制。将日志副本写到多个SSD上去，FaRM可以获得可用性
    和持续性，但也可以作为一个缓存。(？)
        FaRM提供两种机制来改善性能，这只需要对代码做一些局部修改：多次无锁读可以使用一次RDMA操作完成，并且这些读是由
    事务保证严格串行的；支持对象收集和函数迁移来允许应用程序把分布式事务替换成经过优化的单机事务。
    我们在FaRM上设计实现了一个新型哈希表算法，它把hopscotch哈希与链式化和关联性结合起来是的空间利用率高，同时只需要
    少量的RDMA读操作来应用于查询操作：在90%的并发上小型对象的读只需要1.04次RDMA读操作。
    通过利用FaRM对收集相关对象和函数迁移的支持，我们对插入，更新和移除操作进行优化。
    
通信原语：
        FaRM使用单边RDMA读来直接访问数据，并且使用RDMA写来实现一种快速消息传递原语。这个原语使用一个环形缓冲区来实现一个单向信道。
    缓冲区放在receiver上，对于每一对sender和receiver只有一个缓冲区。缓冲区未使用的部分（标记为未处理和未使用）是被清零使得receiver
    能都检测到新的消息。receiver间歇性的从Head位置提取数据来检测新消息。头部中任何非零的值L都表示有一个长度为L的新消息。
    receiver然后就轮询提取直到报文尾部：当结果变为非零时，整个消息就被接收完毕，因为RDMA写是以逐渐增加的地址序列来执行的。
    之后，消息被交付给应用层，并且一旦被应用层处理完之后，receiver就将消息缓冲区清零并且将head指针向前(增长的方向)移动。
        发送者使用RDMA来讲消息写到缓冲区的尾部然后每次发送时都将尾指针向增加的方向移动。发送方会维护接收方头指针的一个本地副本并且从来不会
    在写入消息时越过这个点。接收方通过使用RDMA将当前head的值写到发送方的副本里，稍慢一步告诉发送方经过处理的缓冲区空间已经可用了。
    为了减少中间耗费，接收方只在处理完缓冲区的一半后才更新发送方的副本（头指针）。发送方的头指针副本总是滞后于接收方的头指针，因此也就保证了
    发送方绝不会写覆盖未经处理的消息。
        轮询poll的中间耗费随着信道(channel)数量的增加而线性增长。因此我们从一个线程中建立一个连接远程机器的单信道。在78台机器上我们发现轮询poll的
    中间耗费几乎可以忽略不算。我们也发现在这种规模上，RDMA写和轮询poll要比更复杂的infiniband发送和接受动作显著地表现的更好一些。在大型集群上，
    也许使用RDMA带有immediate的写配上共享接收队列SRQ更好，这会使得轮询poll的中间耗费是一个常量。
        我们的实现使用一个连续的环形缓冲区而不是许多缓冲区连接成一个环状来对于大小变化的消息提供更好的内存利用率。此外，【35】里面接收方在消息中
    外带对发送方头指针的更新数据。
        我们在用40G的RoCE网络连接的20台主机的集群环境下跑了一个微测试来比较FaRM的通信原语和TCP/IP的性能。每台机器运行一定数量的线程，以一种全互联
    的通信模式发送从一个随机的远程机器内存中随机读取一块的请求。图2展示了每台机器的平均请求率，每台机器都已经为了达到峰值吞吐量做了配置优化。
    图左边，packet的速率是FaRM通信原语的瓶颈所在，到了右边，通信瓶颈就是比特率。？？？。单边RDMA读操作在2KB的请求大小下达到了33G的比特率，并且
    在请求大小大于8KB时比特率在35G附近饱和。
        FaRM的基于RDMA消息发送模式在16到512字节范围内比TCP/IP的请求速率快11倍到9倍之间，这个数据大小是数据中心应用的典型规模。单边RDMA读操作在
    数据大小提升到256字节时会获得额外的2倍性能提升，因为它只要求一半的网络包（单边的优势）。我们期望这个性能间的间隔能随着下一代支持4倍消息率的NIC
    能持续增加。单边RDMA读操作不干涉远端的CPU而且基于RDMA的发送消息模式将会是CPU BOUND。
        我们也比较了UDP的吞吐量，并且观察到它比TCP吞吐量的一半还要少。
        图3展示了在极限请求速率和为了最小化延迟而只使用两台机器的环境下的平均请求延迟。TCP/IP在极限请求速率的条件下，延迟至少是基于RDMA的发送消息
    模式在所有请求大小下的145倍。对于请求大小提升到256字节时，通过两个额外的因素使用单边RDMA读来减少延迟。在一个没有加载的系统中（负荷不重的情况下），
    RDMA读的延迟至少比TCP/IP低12倍，并且在所以请求大小的情况下比基于RDMA的消息发送模式要低3倍。微测试表明FaRM的通信原语可以同时取得低延迟和高消息率。
        对于这两种通信原语，取得这样的性能水平是不一般的，需要解决一些问题。第一个问题就是：RDMA操作的性能会随着我们增加为远程访问而注册的内存的数量
    显著下降。原因就是：NIC用完了缓存所有页表的空间。因此它不断地通过PCI总线从系统内存中取页表记录。
        我们通过使用更大的页来减少NIC页表中的记录数量解决记录数量过多的问题。不行的是，windows和linux下现存支持的大页不能消除所有的取操作。
    
