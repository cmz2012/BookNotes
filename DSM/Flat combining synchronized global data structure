摘要：
    可扩展同步化数据结构的实现是出了名的困难。在多核共享内存方面，最近相关工作引入了一种新的同步范式，叫做平面组合，它允许许多并发访问者
    高效的合作来减少在共享锁上的竞争。在这次工作里，我们把这种范式引入另一种领域，在这里面减小通信是最重要的：分布式内存系统。
    我们为容许延迟的PGAS运行时的Grappa实现了一个平面组合框架，并且展示怎么用它来实现同步化全局数据结构。
    我们发现即便使用简单的锁策略，这些平面组合的数据结构扩展到64个结点上也能带来2～100倍的吞吐量提升。
    我们也通过两个简单的图分析来把它转换成应用性能上的提升。Grappa更高的通信开销和结构化并发导致一种新型分布式平面组合，它可以大大地降低
    为了维持全局顺序一致性带来的必要的通信量。
    
介绍：
    划分全局地址空间语言和运行时的目标是提供给程序一个单个共享内存的假象，而实际上是运行在一个分布式内存机器上，比如集群
    这允许程序员编写他们的算法而不需要显示的管理通信。然而，这并没有降低质疑多个并发线程间的一致性的需要。幸运的是，PGAS社区可以利用
    许多致力于解决共享内存问题的工作并且探索不同的开销是怎么导致不同的设计选择的。
    大多数人都认可，最容易判断的一致性模型就是顺序一致性模型，它强制所有的访问都是以程序顺序来提交，并且以全局可序列化顺序出现。
    为了维持顺序一致性，共享数据结构上的操作应该是线性的，也就是说，这些操作是以全局总顺序原子性的出现。
    在物理上共享内存和在划分全局地址空间上，化都呈现出性能问题。最简单的方法是用一个单个全局锁通过简单的互斥独占，来强制确保原子性和线性化
    以这种方法来真正的有序访问通常认为是不可行的，甚至是在物理共享内存上。然而，即便在细粒度无锁同步机制下，随着并发访问者数量的增加，竞争
    也会越来越多，最终使同步操作更加不可行。在多处理结点的集群中大量的并行化和远端同步开销的增长下，问题的严重性就被放大很多。
    一种叫做平面组合的新型同步技术控制线程合作而不是进程。线程把他们的工作交给一个单线程进行代理，这样就有机会把多个请求以特定数据结构的方式
    结合起来，并且执行他们不会出现竞争。这允许甚至一个带有单个全局锁的数据结构比使用细粒度锁或者无锁机制的复杂并发数据结构要扩展的更好。
    我们的工作就是将平面组合应用到PGAS的运行时来减少维持有序一致的数据结构的开销。我们利用Grappa，一个针对细粒度随机访问优化的PGAS运行时库
    它通过高效的在许多轻量级线程间切换来提供容忍长时延的能力。
    我们就正好利用Grappa容许延时的机制来实现许多细粒度同步操作的聚合来实现更高的，可扩展的吞吐量，与此同时还维持线性一致性。
    除此之外，我们还展示了一个一般的平面组合框架怎么能被用于实现多个全局数据结构。
    然后我们更加深入的解释平面组合范式和描述它怎么映射到PGAS模型上去。
    接下来，我们解释一些数据结构在我们的框架下是怎么实现的，和他们在简单的吞吐量负载上是怎么运行的。
    
Grappa：
    非常规应用的特点是：有不可预测的与数据无关的访问模式，空间局部性和时间局部性很差。这类应用程序包括：数据挖据，图分析和不同的学习算法，在高性能
    计算方面的关系越来越紧密。这些程序通常发出对不同来源数据的许多细粒度访问，在多核级别上这是一个问题，但在分布式内存机器上就严重的恶化了。
    通常情况是自然的把一个程序映射到一个PGAS系统上会导致大量的通信和很差的访问模式，但是这类应用又不适用一些典型的优化策略比如：数据划分，影子对象
    和批量同步通信变换。幸运的是，这类应用又有一些公共特征：大量的并行数据访问。这种并行化可以在许多不同方式下被挖据来改善整体吞吐量。
    Grappa是一个为商业集群设计的全局视图的PGAS运行时，从头到尾彻彻底底的重新设计来在非常规应用上取得高性能。
    关键就是容许延时。像读取远端内存的长延迟操作可以通过切换到另一个并发线程的执行来容忍。
    鉴于丰富的并发性，我们有很多机会来以牺牲延迟换取吞吐量的提高。
    尤其是这一点：对远端内存随机访问的吞吐量可以通过延缓通信请求并且把它们聚集成更大的数据包来得到改善。
    在共享内存，划分全局地址空间和消息传递范式上的非常规应用高度优化的实现通常都是以同样的结构做的。  
    Grappa把这些收入囊中并作为它的核心基础，并仅仅要求程序猿来表达Grappa可以利用的并发来提供性能。
    以C++11库实现的Grappa编程接口提供对全局共享内存访问和同步的上层操作，也提供任务和表达并发的并行循环结构。
    除此之外，Grappa的标准库也包括管理全局堆，存储像compare-and-swap这样的远程同步操作和一些同步全局数据结构的函数库。
    这些特点使它很适合实现一些下一代PGAS语言，像chapel 和x10。
    下面的章节将会解释Grappa的执行模型和目前的C++编程接口。
    
    任务和worker：
    Grappa使用一个任务并行的编程模型来更容易的表达并发。一个任务就是一个带有一些状态和要执行的函数的函数对象。任务也许会阻塞在远程访问或者同步操作
    上。Grappa运行时有一个轻量级线程系统，它使用预取来在单核上扩展到数千个线程而在上下文切换时间上只有微小的增加。
    运行的时候，worker线程从一个队列中拉取程序猿指定的任务并将它们执行完毕。当一个任务阻塞时，执行这个任务的worker线程就自动挂起直到被某些事件
    再次唤醒，在此之间不消耗任何计算资源。
    聚集通信：
    Grappa中最基本的通信单元是一个active message。为了高效的使用高性能系统中的网络，（这些网络通常仅仅在消息大小是64KB类别上能取得最大带宽）
    Grappa中所有的通信都是通过一个聚集层来发送的，这个聚集层会自动缓存发往同一目的地的消息。
    全局内存：
    在划分全局地址空间的模式下，Grappa提供一个散落在集群中节点的物理内存的全局地址空间。每个节点持有内存的一部分，这片内存是分成当前核的worker的
    执行栈，与核相关的本地堆和一片全局堆。
    系统中任何核的所有上述内存都可以通过使用全局地址来寻址，全局地址编码核和核上的地址。除此之外，全局堆的地址是以block-cyclic方式划分的，以至于
    一次大型分配是自动分布在许多结点上。对于非常规应用，这有助于避免出现热点并且对于随机访问通常是足够的。
    Grappa强制严格独立性--即便是在同一片物理内存上的进程间，所有的访问都必须被持有这片内存的核通过一个消息来完成才行。
    然而在编程层次上，这个是隐藏在高层的远程操作背后，在Grappa中叫做代理操作。（意思就是说编程人员根本不知道他要访问的是远程还是本地内存，所以
    统一使用远程操作：发送消息）
    图1展示一个代理读操作的例子，它阻塞这个调用任务并且给要读的内存的持有者发送一个消息，然后这个持有者会发送一个带有数据的回复并唤醒这个调用者。
    
    平面结合：
    在最基本的层次上，平面组合的概念就是使得线程间开启合作而不是竞争关系。
    这样带来的好处可以分为为三个方面：
    改善局部性，降低同步和与数据结构相关的优化。
    我们会探索这在传统共享内存系统中是怎么生效的，然后描述同样的概念是怎么能被应用到分布式内存中去。
    
    物理共享内存：
    仅仅将工作交给另一个核代理，局部性可以得到改善，同步也会减少。考虑图2中的共享同步栈，有预分配的存储和通过锁保护的栈顶指针。没有flat combining
    的话，无论何时线程想要将一些东西放进栈里，它就必须获得锁，把值放进存储数组里，将栈顶指针向上顶，然后释放这个锁。当多个线程竞争这个锁的时候，除了
    一个以外所有的线程都会竞争失败然后重试，每次尝试获取锁都会带来昂贵的memory fence（串行化加载与存储操作）并且消耗带宽，随着线程数量的增加，成功
    的因子就会骤然下降。相反，在平面组合下，线程将请求放到公共链表里。他们都尝试获取锁，并且成功的那个线程就成为了combiner。失败者不再重试，而是在
    他们的请求上自旋等待公共记录被填满。这个combiner遍历公共链表，执行所有的请求，完成的时候就释放这个锁。这使得一个线程在cache中保存数据结构，减小了
    不同核上线程间的thrashing。它也减少了在锁上的竞争，但是引入了一个新的同步点---添加到公共链表。然而，如果一个线程执行多个操作，它可以将它的公共
    记录留在链表上，分期偿还这个同步消耗。（意思就是说我虽然一次同步带来的消耗比较大，但是均摊到我多个执行操作上时得到的消耗就比原来的机制很小了）
    公共链表机制可以用其他数据结构来重用，根据需要来保存对方进而实现自己更加灵活的同步。
    上述的代理操作例子是在自行强制发生的。然而，先前工作的关键就是：特定数据结构的优化可以被实现来更加高效的执行这个combined操作。
    随着这个combiner遍历公共链表，它把每个非空的公共记录归并成一个合并的操作。在图2中展示的栈的例子中，它遍历链表时，线程4仍然跟踪它自己临时栈上的
    操作，当它遇到线程2的pop操作时，它识别出它可以用刚刚从线程3处理的push操作来立刻满足这个pop操作，因此它填满线程3和线程2的公共记录并让他们继续执行
    遍历完剩下的公共链表后，线程向实际的数据结构发出合并后的操作，在这个例子中，两个不匹配的push被添加到栈的顶端。
    在栈这个例子上，合并的是以来自于push和pop匹配的形式，但许多数据结构有其他的操作可以被匹配的方式。
    
    Grappa：
    在PGAS环境中，尤其是在Grappa中，全局同步带来的消耗和并发的数量要比共享内存中的同步和并发量更大。
    每个核心有数千个线程，在一个相当规模的集群上随随便便就会有数百万的worker。平面组合在这有很大的机会能取得利益，就是能大显身手，但是也带来新的挑战。
    图3展示了一个简单的PGAS转换到共享内存栈.(from earlier)
    
