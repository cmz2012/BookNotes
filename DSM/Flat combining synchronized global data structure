摘要：
    可扩展同步化数据结构的实现是出了名的困难。在多核共享内存方面，最近相关工作引入了一种新的同步范式，叫做平面组合，它允许许多并发访问者
    高效的合作来减少在共享锁上的竞争。在这次工作里，我们把这种范式引入另一种领域，在这里面减小通信是最重要的：分布式内存系统。
    我们为容许延迟的PGAS运行时的Grappa实现了一个平面组合框架，并且展示怎么用它来实现同步化全局数据结构。
    我们发现即便使用简单的锁策略，这些平面组合的数据结构扩展到64个结点上也能带来2～100倍的吞吐量提升。
    我们也通过两个简单的图分析来把它转换成应用性能上的提升。Grappa更高的通信开销和结构化并发导致一种新型分布式平面组合，它可以大大地降低
    为了维持全局顺序一致性带来的必要的通信量。
    
介绍：
    划分全局地址空间语言和运行时的目标是提供给程序一个单个共享内存的假象，而实际上是运行在一个分布式内存机器上，比如集群
    这允许程序员编写他们的算法而不需要显示的管理通信。然而，这并没有降低质疑多个并发线程间的一致性的需要。幸运的是，PGAS社区可以利用
    许多致力于解决共享内存问题的工作并且探索不同的开销是怎么导致不同的设计选择的。
    大多数人都认可，最容易判断的一致性模型就是顺序一致性模型，它强制所有的访问都是以程序顺序来提交，并且以全局可序列化顺序出现。
    为了维持顺序一致性，共享数据结构上的操作应该是线性的，也就是说，这些操作是以全局总顺序原子性的出现。
    在物理上共享内存和在划分全局地址空间上，化都呈现出性能问题。最简单的方法是用一个单个全局锁通过简单的互斥独占，来强制确保原子性和线性化
    以这种方法来真正的有序访问通常认为是不可行的，甚至是在物理共享内存上。然而，即便在细粒度无锁同步机制下，随着并发访问者数量的增加，竞争
    也会越来越多，最终使同步操作更加不可行。在多处理结点的集群中大量的并行化和远端同步开销的增长下，问题的严重性就被放大很多。
    一种叫做平面组合的新型同步技术控制线程合作而不是进程。线程把他们的工作交给一个单线程进行代理，这样就有机会把多个请求以特定数据结构的方式
    结合起来，并且执行他们不会出现竞争。这允许甚至一个带有单个全局锁的数据结构比使用细粒度锁或者无锁机制的复杂并发数据结构要扩展的更好。
    我们的工作就是将平面组合应用到PGAS的运行时来减少维持有序一致的数据结构的开销。我们利用Grappa，一个针对细粒度随机访问优化的PGAS运行时库
    它通过高效的在许多轻量级线程间切换来提供容忍长时延的能力。
    我们就正好利用Grappa容许延时的机制来实现许多细粒度同步操作的聚合来实现更高的，可扩展的吞吐量，与此同时还维持线性一致性。
    除此之外，我们还展示了一个一般的平面组合框架怎么能被用于实现多个全局数据结构。
    然后我们更加深入的解释平面组合范式和描述它怎么映射到PGAS模型上去。
    接下来，我们解释一些数据结构在我们的框架下是怎么实现的，和他们在简单的吞吐量负载上是怎么运行的。
    
Grappa：
    非常规应用的特点是：有不可预测的与数据无关的访问模式，空间局部性和时间局部性很差。这类应用程序包括：数据挖据，图分析和不同的学习算法，在高性能
    计算方面的关系越来越紧密。这些程序通常发出对不同来源数据的许多细粒度访问，在多核级别上这是一个问题，但在分布式内存机器上就严重的恶化了。
    通常情况是自然的把一个程序映射到一个PGAS系统上会导致大量的通信和很差的访问模式，但是这类应用又不适用一些典型的优化策略比如：数据划分，影子对象
    和批量同步通信变换。幸运的是，这类应用又有一些公共特征：大量的并行数据访问。这种并行化可以在许多不同方式下被挖据来改善整体吞吐量。
    Grappa是一个为商业集群设计的全局视图的PGAS运行时，从头到尾彻彻底底的重新设计来在非常规应用上取得高性能。
    关键就是容许延时。像读取远端内存的长延迟操作可以通过切换到另一个并发线程的执行来容忍。
    鉴于丰富的并发性，我们有很多机会来以牺牲延迟换取吞吐量的提高。
    尤其是这一点：对远端内存随机访问的吞吐量可以通过延缓通信请求并且把它们聚集成更大的数据包来得到改善。
    在共享内存，划分全局地址空间和消息传递范式上的非常规应用高度优化的实现通常都是以同样的结构做的。     
